# LLM-Table-Survey
## Table of Contents

- [LLM-Table-Survey](#llm-table-survey)
  - [Table of Contents](#table-of-contents)
  - [Methods](#methods)
  - [Dataset \& Benchmark](#dataset--benchmark)

## Methods


| Name                     | Tittle                                                                                                                  | Keywords                                                                      | Artifact                                                                | Paper                                                                                                   |
|--------------------------|-------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------|-------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------|
| Codex                    | Evaluating Large Language Models Trained on Code                                                                        | Code Generation                                                               | -                                                                       | [arXiv 21](https://arxiv.org/abs/2107.03374)                                                            |
| GPT-3                    | Language Models are Few-Shot Learners                                                                                   | LLM, in-context learning                                                      |  -                                                                      | [NeurIPS 20](https://proceedings.neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf) |
| BERT                     | BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding                                        | Pre-training                                                                  | [Model](https://huggingface.co/docs/transformers/model_doc/bert)                         | [NAACL 19](https://arxiv.org/abs/1810.04805)                            |
| SpreadsheetCoder         | SpreadsheetCoder: Formula Prediction from Semi-structured Context                                                       | Spreadsheet formula prediction                                                                      | [Code](https://github.com/google-research/google-research/tree/master/spreadsheet_coder) | [ICML 21](https://proceedings.mlr.press/v139/chen21m/chen21m.pdf)                     |
| TURL                     | TURL: Table Understanding through Representation Learning                                                               | Table Pre-training                                                            | [Code](https://github.com/sunlab-osu/TURL)                                               | [VLDB 20](https://www.vldb.org/pvldb/vol14/p307-deng.pdf)               |
| TaPEx                    | TAPEX: Table Pre-training via Learning a Neural SQL Executor                                                            | Table Pre-training                                                                          | [Code](https://github.com/microsoft/Table-Pretraining)                         | [ICLR 22](https://openreview.net/pdf?id=O50443AsCP)                     |
| TaBERT                   | TaBERT: Pretraining for Joint Understanding of Textual and Tabular Data                                                 | Table Pre-training                                                                                                     | [Code](http://fburl.com/TaBERT)                                                | [ACL 20](https://aclanthology.org/2020.acl-main.745/)                   |
| TaPas                    | TaPas: Weakly Supervised Table Parsing via Pre-training                                                                 | Table Pre-training                                                            | [Code](https://github.com/google-research/tapas)                                         | [ACL 20](https://aclanthology.org/2020.acl-main.398)                    |
| TABBIE                   | TABBIE: Pretrained Representations of Tabular Data                                                                      | Table Pre-training                                                            | [Code](https://github.com/SFIG611/tabbie)                                                | [ACL 21](https://aclanthology.org/2021.naacl-main.270)                  |
| RESDSQL                  | RESDSQL: Decoupling Schema Linking and Skeleton Parsing for Text-to-SQL                                                 | text-to-SQL fine-tuning                                                                     | [Code](https://github.com/RUCKBReasoning/RESDSQL)                              | [AAAI 23](https://ojs.aaai.org/index.php/AAAI/article/view/26535/26307) |
| FLAN                     | Finetuned Language Models Are Zero-Shot Learners                                                                        | Instruction-tuning                                                                                                     | [Code](https://github.com/google-research/FLAN)                                | [ICLR 22](https://openreview.net/pdf?id=gEZrGCozdqR)                    |
| Chain-of-thought | Chain-of-thought prompting elicits reasoning in large language models | Step-by-step Reasoning| - | [NeurIPS 22](https://proceedings.neurips.cc/paper_files/paper/2022/file/9d5609613524ecf4f15af0f7b31abca4-Paper-Conference.pdf) |
| Least-to-most | Least-to-most prompting enables complex reasoning in large language models | Prompting, Decompose | - | [ICLR 23](https://openreview.net/pdf?id=WZH7099tgfM) |
| Self-consistency | Self-consistency improves chain of thought reasoning in language models | Reason with votes | - | [ICLR 23](https://openreview.net/pdf?id=1PL1NIMMrw) |
| Table-GPT                | Table-GPT: Table-tuned GPT for Diverse Table Tasks                                                                      | Table Instruction-tuning                                                                    | -                                                                              | [arXiv 23](https://arxiv.org/abs/2310.09263v1)                          |
| TableLlama               | TableLlama: Towards Open Large Generalist Models for Tables                                                             | Table Instruction-tuning                                                                                                     | [Model](https://huggingface.co/osunlp/TableLlama)                              | [arXiv 23](https://arxiv.org/abs/2311.09206)                            |
| UnifiedSKG               | UnifiedSKG: Unifying and Multi-Tasking Structured Knowledge Grounding with Text-to-Text Language Models                 | Table Instruction-tuning                                                                                                     | [Code](https://github.com/xlang-ai/UnifiedSKG)                                 | [EMNLP 22](https://aclanthology.org/2022.emnlp-main.39/)                |
| Code Llama | Code Llama: Open Foundation Models for Code | Code | [Code](https://github.com/facebookresearch/codellama) | [arXiv 23](https://arxiv.org/pdf/2308.12950.pdf) |
| Magicoder | Magicoder: Source Code Is All You Need | Code Instruction-tuning | [Code](https://github.com/ise-uiuc/magicoder) [Model](https://huggingface.co/ise-uiuc/Magicoder-CL-7B) | [arXiv 23](https://arxiv.org/pdf/2312.02120.pdf) |
| Lemur | Lemur: Harmonizing Natural Language and Code for Language Agents | Code Instruction-tuning | [Code](https://github.com/OpenLemur/Lemur) [Model](https://huggingface.co/OpenLemur) | [ICLR 24](https://openreview.net/pdf?id=hNhwSmtXRh) |
| ReAct                    | ReAct: Synergizing Reasoning and Acting in Language Models                                                              | Agent Framework                                                                                                              | [Code](https://react-lm.github.io/)                                            | [ICLR 23](https://arxiv.org/abs/2210.03629)                             |
| Dater                    | Large Language Models are Versatile Decomposers: Decompose Evidence and Questions for Table-based Reasoning             | Prompting, Decomposing                                                                                                 | [Code](https://github.com/AlibabaResearch/DAMO-ConvAI)                         | [SIGIR 23](https://arxiv.org/abs/2301.13808)                            |
| StructGPT                | StructGPT: A General Framework for Large Language Model to Reason over Structured Data                                  | Prompting, Structured Knowledge                                               | [Code](https://github.com/RUCAIBox/StructGPT)                                            | [EMNLP 23](https://aclanthology.org/2023.emnlp-main.574/)               |
| DAIL-SQL                 | Text-to-SQL Empowered by Large Language Models: A Benchmark Evaluation                                                  | Prompting, text-to-SQL                                                                     | [Code](https://github.com/taoyds/test-suite-sql-eval)                                    | [arXiv 23](https://arxiv.org/abs/2308.15363)                            |
| C3                       | C3: Zero-shot Text-to-SQL with ChatGPT                                                                                  | Prompting                                                                     | [Code](https://arxiv.org/abs/2307.07306)                                                 | [arXiv 23](https://arxiv.org/abs/2307.07306)                            |
| DIN-SQL                  | DIN-SQL: Decomposed In-Context Learning of Text-to-SQL with Self-Correction                                             | Prompting, Decompose                                                                                                   | [Code](https://github.com/MohammadrezaPourreza/Few-shot-NL2SQL-with-prompting) | [NeurIPS 23](https://arxiv.org/abs/2304.11015)                          |
| Prompt Design Strategies | Enhancing Text-to-SQL Capabilities of Large Language Models: A Study on Prompt Design Strategies                        | Prompting, text-to-SQL                                                                                                                 | [Code](https://github.com/linyongnan/STRIKE)                                   | [EMNLP 23](https://aclanthology.org/2023.findings-emnlp.996.pdf)        |
| Binder                   | Binding Language Models in Symbolic Languages                                                                           | Prompting                                                                        | [Code](https://github.com/xlang-ai/Binder)                                               | [ICLR 23](https://arxiv.org/abs/2210.02875)                             |
| Data-Copilot             | Data-Copilot: Bridging Billions of Data and Humans with Autonomous Workflow                                             | Agent, Data Visualization                                                                                              | [Code](https://github.com/zwq2018/Data-Copilot)                                | [arXiv 23](https://arxiv.org/abs/2306.07209)                            |
| SheetCopilot             | SheetCopilot: Bringing Software Productivity to the Next Level through Large Language Models                            | Agent, Spreadsheet                                                                    | [Code](https://sheetcopilot.github.io/)                                        | [NeurIPS 23](https://arxiv.org/abs/2305.19308)                          |
| ReAcTable                | ReAcTable: Enhancing ReAct for Table Question Answering                                                                 | Agent, ReAct                                                                                                           | [Code](https://github.com/yunjiazhang/ReAcTable.git)                           | [arXiv 23](https://arxiv.org/abs/2310.00815)                            |
| TAP4LLM | TAP4LLM: Table Provider on Sampling, Augmenting, and Packing Semi-structured Data for Large Language Model Reasoning | Table Augmentation | | [arXiv 23](https://arxiv.org/pdf/2312.09039.pdf) |
| DB-GPT                   | DB-GPT: Empowering Database Interactions with Private Large Language Models                                             | Industry Framework                                                                                                     | [Code](https://github.com/eosphoros-ai/DB-GPT)                                 | [arXiv 23](https://arxiv.org/abs/2312.17449)                            |
| DPR                      | Dense Passage Retrieval for Open-Domain Question Answering                                                              | Retrieval-Augmented Generation                                                | [Code](https://github.com/facebookresearch/DPR)                                          | [EMNLP 20](https://arxiv.org/abs/2004.04906)                            |
| ITR                      | An Inner Table Retriever for Robust Table Question Answering                                                            | Retrieval                                                                                                              | [Code](https://github.com/amazon-science/robust-tableqa)                       | [ACL 23](https://aclanthology.org/2023.acl-long.551/)                   |
| LI-RAGE                  | LI-RAGE: Late Interaction Retrieval Augmented Generation with Explicit Signals for Open-Domain Table Question Answering | RAG + Table                                                                                    | [Code](https://github.com/amazon-science/robust-tableqa)                       | [ACL 23](https://aclanthology.org/2023.acl-short.133/)                  |

## Dataset & Benchmark


| Name               | Keywords                  | Artifact                                                                 | Paper                                                       |
|--------------------|---------------------------|--------------------------------------------------------------------------|-------------------------------------------------------------|
| MBPP               | Code    | [link](https://huggingface.co/datasets/mbpp)                             | [arXiv 21](https://arxiv.org/abs/2108.07732)                |
| HumanEval          | Code    | [link](https://github.com/openai/human-eval)                         | [arXiv 21](https://arxiv.org/abs/2107.03374)                |
| Dr.Spider         | Text-to-SQL, Robustness               | [link](https://github.com/awslabs/diagnostic-robustness-text-to-sql) | [ICLR 23](https://arxiv.org/abs/2301.08881)                 |
| TabFact            | Table QA                  | [link](https://tabfact.github.io/)                                   | [ICLR 20](https://arxiv.org/abs/1909.02164)                 |
| HyBirdQA           | Table QA                  | [link](https://github.com/wenhuchen/HybridQA)                        | [EMNLP 20](https://arxiv.org/abs/2004.07347)                |
| AnaMeta            | Table Metadata            | [link](https://github.com/microsoft/AnaMeta)                         | [ACL 23](https://arxiv.org/abs/2209.00946)                  |
| InfiAgent-DABench  | Data Analysis    | [link](https://arxiv.org/abs/2401.05507)                             | [arXiv 24](https://arxiv.org/abs/2401.05507)                |
| GitTables          | GitHub CSVs    | [link](https://gittables.github.io/)                                 | [SIGMOD 23](https://arxiv.org/abs/2106.07258)              |
| DS-1000            | Data Analysis    | [link](https://ds1000-code-gen.github.io/)                           | [ICML 23](https://arxiv.org/abs/2211.11501)                 |
| WDC                | Web Table                 | [link](https://webdatacommons.org/)                                  | [WWW 16](https://dl.acm.org/doi/10.1145/2872518.2889386)    |
| BIRD               | Text-to-SQL               | [link](https://bird-bench.github.io/)                                | [NeurIPS 23](https://arxiv.org/abs/2305.03111)              |
| DART               | Table-to-text             | [link](https://github.com/Yale-LILY/dart)                            | [NAACL 21](https://aclanthology.org/2021.naacl-main.37/)                |
| FetaQA             | Table QA                  | [link](https://github.com/Yale-LILY/FeTaQA)                          | [TACL 22](https://aclanthology.org/2022.tacl-1.3/)                 |
| ToTTo              | Table-to-text             | [link](https://github.com/google-research-datasets/totto)            | [EMNLP 20](https://aclanthology.org/2020.emnlp-main.89/)                |
| WiKiTableQuestions | Table QA                  | [link](https://github.com/ppasupat/WikiTableQuestions)               | [ACL 15](https://aclanthology.org/P15-1142/)                  |
| sheetperf          | Spreadsheet              | [link](https://github.com/dataspread/spreadsheet-benchmark)          | [SIGMOD 20](https://dl.acm.org/doi/10.1145/3318464.3389782) |
| GPT4Table          | Table QA,   Table-to-text | [link](https://github.com/Y-Sui/GPT4Table)                           | [WSDM 24](https://arxiv.org/abs/2305.13062)                 |
| Spider             | Text-to-SQL               | [link](https://yale-lily.github.io/spider)                           | [EMNLP 18](https://arxiv.org/abs/1809.08887)                |
| RobuT              | Table QA                  | [link](https://github.com/yilunzhao/RobuT)                           | [ACL 23](https://arxiv.org/abs/2306.14321)                  |
| WiKiSQL            | Table QA,Text-to-SQL      | [link](https://github.com/salesforce/WikiSQL)                        | [arXiv 17](https://arxiv.org/abs/1709.00103)                                                |
| Observatory                           | Table Embedding Benchmark | [Code](https://github.com/superctj/observatory)                                          | [VLDB 24](https://arxiv.org/abs/2310.07736v3)                                                           |
| TableInstruct                           | Table Instruction Tuning Benchmark | [link](https://huggingface.co/datasets/osunlp/TableInstruct)                                          | [arXiv 23](https://arxiv.org/pdf/2311.09206.pdf)                                                           |
